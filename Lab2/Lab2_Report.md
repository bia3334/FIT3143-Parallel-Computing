# FIT3143 Lab 2 Report: Threads & OpenMP
## Finding Prime Numbers with Parallel Computing

**Student Name:** Tien Hung Nguyen  
**Student ID:** 35499435
**Email:** tngu0534@student.monash.edu  
**Date:** 18/8/2025

---

## Executive Summary

This report presents a comparative analysis of parallel computing approaches for finding prime numbers using POSIX Threads and OpenMP. The study evaluates performance, scalability, and implementation efficiency across different thread configurations on a system with 20 available CPU cores.

**Key Findings:**
- OpenMP demonstrates superior performance with up to 3.00x speedup
- POSIX Threads implementation shows performance degradation in all test cases
- Optimal performance achieved with 8 threads using OpenMP
- Dynamic scheduling significantly outperforms static partitioning

---

## 1. Introduction

### 1.1 Objectives
- Implement parallel algorithms using POSIX Threads and OpenMP
- Analyze performance characteristics and scalability
- Compare different parallelization approaches
- Evaluate the effectiveness of task distribution strategies

### 1.2 Problem Statement
Find all prime numbers strictly less than integer n (n = 1,000,000) using:
1. Serial implementation (baseline)
2. POSIX Threads parallel implementation
3. OpenMP parallel implementation

### 1.3 System Specifications
- **CPU Cores:** 20 available cores
- **Architecture:** x86_64
- **Operating System:** Linux (WSL2)
- **Compiler:** GCC with optimization flags

---

## 2. Methodology

### 2.1 Prime Number Algorithm
All implementations use the same core algorithm:
```c
int is_prime(int num) {
    if (num < 2) return 0;
    if (num == 2) return 1;
    if (num % 2 == 0) return 0;
    int limit = (int)sqrt(num);
    for (int i = 3; i <= limit; i += 2) {
        if (num % i == 0) return 0;
    }
    return 1;
}
```

### 2.2 Implementation Approaches

#### 2.2.1 Serial Implementation (Task 1)

**Design Philosophy:**
The serial implementation serves as the **baseline reference** for all performance comparisons. It uses a straightforward sequential approach with optimized prime checking algorithm and flexible output handling based on input size.

**Key Design Features:**

1. **Optimized Prime Checking Algorithm:**
   - **Early termination:** Returns immediately for numbers < 2
   - **Even number optimization:** Only checks odd divisors after 2
   - **Square root limit:** Reduces checking range significantly
   - **Skip even numbers:** Only tests odd potential divisors

2. **Adaptive Output Strategy:**
   - **Small inputs (n â‰¤ 1,000,000):** Display primes in console with comma separation
   - **Large inputs (n > 1,000,000):** Write primes to file for better performance
   - **Sorted output:** Natural ascending order due to sequential processing

3. **Memory Management:**
   - **Dynamic allocation:** Array size based on input n
   - **Single allocation:** One contiguous memory block
   - **Efficient storage:** Only stores actual prime numbers found

**Complete Implementation:**

```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <time.h>
#include <unistd.h>

int is_prime(int num) {
    if (num < 2) return 0;
    if (num == 2) return 1;
    if (num % 2 == 0) return 0;
    int limit = (int)sqrt(num);
    for (int i = 3; i <= limit; i += 2) {
        if (num % i == 0) return 0;
    }
    return 1;
}

int main() {
    int n;
    printf("Enter n: ");
    scanf("%d", &n);

    int cores = sysconf(_SC_NPROCESSORS_ONLN);
    printf("Available CPU cores: %d\n", cores);

    // Allocate memory for storing primes
    int *primes = malloc(n * sizeof(int));
    if (!primes) {
        printf("Memory allocation failed\n");
        return EXIT_FAILURE;
    }
    int count = 0;

    // Start timing
    clock_t start = clock();

    // Find primes serially
    for (int i = 2; i < n; i++) {
        if (is_prime(i)) {
            primes[count++] = i;
        }
    }

    clock_t end = clock();
    double elapsed_time = ((double)(end - start)) / CLOCKS_PER_SEC;

    // For small n, print to console; for large n, write to file
    if (n <= 1000000) {
        printf("Prime numbers less than %d: ", n);
        for (int i = 0; i < count; i++) {
            printf("%d", primes[i]);
            if (i < count - 1) printf(", ");
        }
        printf("\n");
    } else {
        // Write results to file for large n
        FILE *outfile = fopen("primes_serial.txt", "w");
        if (!outfile) {
            perror("File opening failed");
            free(primes);
            return EXIT_FAILURE;
        }

        for (int i = 0; i < count; i++) {
            fprintf(outfile, "%d\n", primes[i]);
        }
        fclose(outfile);
        printf("Primes written to primes_serial.txt\n");
    }

    printf("Time taken (serial): %.4f seconds\n", elapsed_time);
    printf("Total primes found: %d\n", count);

    free(primes);
    return 0;
}
```

**Algorithm Efficiency Analysis:**
- **Time Complexity:** O(nâˆšn) for checking all numbers up to n
- **Space Complexity:** O(Ï€(n)) where Ï€(n) is the number of primes â‰¤ n
- **Optimization Level:** Well-optimized for single-threaded execution
- **Cache Efficiency:** Sequential memory access pattern

**Advantages:**
- **Simplicity:** Easy to understand and debug
- **Predictable performance:** Consistent execution time
- **Memory efficient:** Single allocation, no overhead
- **Optimal for small datasets:** No parallelization overhead

**Limitations:**
- **Single-threaded:** Cannot utilize multiple CPU cores
- **Fixed algorithm:** No adaptive optimization during runtime
- **Scalability:** Performance degrades linearly with input size

#### 2.2.2 POSIX Threads Implementation (Task 2)

**Design Philosophy:**
The POSIX Threads implementation follows a **divide-and-conquer** approach with static range partitioning. Each thread is assigned a contiguous range of numbers to check for primality, ensuring no overlap and complete coverage of the search space.

**Key Design Decisions:**

1. **Data Structure Design:**
```c
typedef struct {
    int start;        // Starting number for this thread
    int end;          // Ending number (exclusive)
    int *primes;      // Local array to store found primes
    int *count;       // Pointer to count of primes found
} ThreadData;
```

2. **Range Partitioning Strategy:**
- **Total range:** Numbers from 2 to n-1 (avoiding 0 and 1)
- **Division method:** `total_range = n - 2; range = total_range / num_threads`
- **Thread assignment:** Thread `t` processes `[2 + t*range, 2 + (t+1)*range)`
- **Last thread handling:** Handles any remaining numbers due to integer division

3. **Memory Management Approach:**
- **Per-thread allocation:** Each thread gets its own result array
- **Size estimation:** Over-allocate `range` integers per thread
- **Independence:** No shared memory between threads during computation
- **Sequential merging:** Results combined after all threads complete

**Example with n=100, 4 threads:**
- Thread 0: checks numbers 2-26 (range: 24 numbers)
- Thread 1: checks numbers 26-50 (range: 24 numbers)  
- Thread 2: checks numbers 50-74 (range: 24 numbers)
- Thread 3: checks numbers 74-100 (range: 26 numbers, handles remainder)

**Complete Implementation:**

```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <pthread.h>
#include <time.h>
#include <unistd.h>

typedef struct {
    int start;
    int end;
    int *primes;
    int *count;
} ThreadData;

int is_prime(int num) {
    if (num < 2) return 0;
    if (num == 2) return 1;
    if (num % 2 == 0) return 0;
    int limit = (int)sqrt(num);
    for (int i = 3; i <= limit; i += 2) {
        if (num % i == 0) return 0;
    }
    return 1;
}

void* find_primes(void* arg) {
    ThreadData* data = (ThreadData*)arg;
    int idx = 0;
    for (int i = data->start; i < data->end; i++) {
        if (is_prime(i)) {
            data->primes[idx++] = i;
        }
    }
    *(data->count) = idx; // number of primes found by this thread
    pthread_exit(NULL);
}

int main() {
    int n, num_threads;
    printf("Enter n: ");
    scanf("%d", &n);
    printf("Enter number of threads: ");
    scanf("%d", &num_threads);

    int cores = sysconf(_SC_NPROCESSORS_ONLN);
    printf("Available CPU cores: %d\n", cores);

    pthread_t threads[num_threads];
    ThreadData thread_data[num_threads];
    int *all_primes[num_threads];
    int counts[num_threads];

    clock_t start = clock();

    // Start from 2 (first prime) and distribute range
    int total_range = n - 2;
    int range = total_range / num_threads;
    for (int t = 0; t < num_threads; t++) {
        int start_num = 2 + t * range;
        int end_num = (t == num_threads - 1) ? n : start_num + range;
        all_primes[t] = malloc(range * sizeof(int)); // over-allocate
        counts[t] = 0;
        thread_data[t] = (ThreadData){start_num, end_num, all_primes[t], &counts[t]};
        pthread_create(&threads[t], NULL, find_primes, &thread_data[t]);
    }

    for (int t = 0; t < num_threads; t++) {
        pthread_join(threads[t], NULL);
    }

    clock_t end = clock();
    double elapsed_time = ((double)(end - start)) / CLOCKS_PER_SEC;

    // Calculate total count
    int total_primes = 0;
    for (int t = 0; t < num_threads; t++) {
        total_primes += counts[t];
    }

    // Merge results in ascending order (already sorted per thread)
    FILE *outfile = fopen("primes_parallel.txt", "w");
    if (!outfile) {
        perror("File opening failed");
        return EXIT_FAILURE;
    }
    for (int t = 0; t < num_threads; t++) {
        for (int i = 0; i < counts[t]; i++) {
            fprintf(outfile, "%d\n", all_primes[t][i]);
        }
        free(all_primes[t]);
    }
    fclose(outfile);

    printf("Time taken (parallel): %.4f seconds\n", elapsed_time);
    printf("Total primes found: %d\n", total_primes);
    printf("Primes written to primes_parallel.txt\n");

    return 0;
}
```

**Advantages of This Approach:**
- **Thread safety:** No shared memory during computation
- **Simplicity:** Straightforward implementation and debugging
- **Predictable behavior:** Deterministic thread assignment
- **Natural ordering:** Results are already sorted within each thread

**Disadvantages of This Approach:**
- **Load imbalance:** Prime density varies across number ranges
- **Memory overhead:** Multiple allocations and separate arrays
- **Cache inefficiency:** Threads may work on distant memory regions
- **Static partitioning:** Cannot adapt to actual workload distribution

#### 2.2.3 OpenMP Implementation (Task 3)

**Design Philosophy:**
The OpenMP implementation leverages **compiler directives** and **runtime optimization** to achieve efficient parallelization with minimal code changes. It uses dynamic scheduling for optimal load balancing and shared memory for efficient resource utilization.

**Key Design Features:**

1. **OpenMP Pragma-Based Parallelization:**
   - **Automatic thread management:** OpenMP handles thread creation/destruction
   - **Compiler optimization:** Leverages OpenMP runtime optimizations
   - **Directive-based:** Minimal code changes from serial version
   - **Portable:** Works across different OpenMP-compliant compilers

2. **Dynamic Scheduling Strategy:**
   ```c
   #pragma omp parallel for schedule(dynamic, 100)
   ```
   - **Dynamic load balancing:** Work units redistributed at runtime
   - **Chunk size 100:** Optimal balance between overhead and distribution
   - **Adaptive:** Automatically adjusts to varying workloads
   - **NUMA-aware:** Runtime can optimize for memory locality

3. **Shared Memory with Critical Sections:**
   ```c
   #pragma omp critical
   {
       primes[count++] = i;
   }
   ```
   - **Shared result array:** Single memory allocation for all threads
   - **Thread-safe updates:** Critical section prevents race conditions
   - **Minimal synchronization:** Only during result storage
   - **Cache-friendly:** Threads work on shared data structure

4. **High-Precision Timing:**
   ```c
   double start_time = omp_get_wtime();
   // ... parallel computation ...
   double end_time = omp_get_wtime();
   ```
   - **Wall-clock time:** More accurate for parallel execution
   - **High resolution:** Better precision than clock()
   - **Thread-safe:** Each thread can call independently

**Complete Implementation:**

```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <omp.h>
#include <time.h>
#include <unistd.h>

int is_prime(int num) {
    if (num < 2) return 0;
    if (num == 2) return 1;
    if (num % 2 == 0) return 0;
    int limit = (int)sqrt(num);
    for (int i = 3; i <= limit; i += 2) {
        if (num % i == 0) return 0;
    }
    return 1;
}

int compare_ints(const void *a, const void *b) {
    return (*(int*)a - *(int*)b);
}

int main() {
    int n, num_threads;
    printf("Enter n: ");
    scanf("%d", &n);
    printf("Enter number of threads: ");
    scanf("%d", &num_threads);

    int cores = sysconf(_SC_NPROCESSORS_ONLN);
    printf("Available CPU cores: %d\n", cores);

    // Set the number of threads for OpenMP
    omp_set_num_threads(num_threads);

    // Allocate memory for storing primes
    int *primes = malloc(n * sizeof(int));
    if (!primes) {
        printf("Memory allocation failed\n");
        return EXIT_FAILURE;
    }
    int count = 0;

    // Start timing
    double start_time = omp_get_wtime();

    // Using OpenMP parallel for with dynamic scheduling for better load balancing
    #pragma omp parallel for schedule(dynamic, 100)
    for (int i = 2; i < n; i++) {
        if (is_prime(i)) {
            #pragma omp critical
            {
                primes[count++] = i;
            }
        }
    }

    double end_time = omp_get_wtime();
    double elapsed_time = end_time - start_time;

    // Sort the results (parallel execution doesn't guarantee order)
    if (count > 1) {
        qsort(primes, count, sizeof(int), compare_ints);
    }

    // Write results to file
    FILE *outfile = fopen("primes_openmp.txt", "w");
    if (!outfile) {
        perror("File opening failed");
        free(primes);
        return EXIT_FAILURE;
    }

    for (int i = 0; i < count; i++) {
        fprintf(outfile, "%d\n", primes[i]);
    }
    fclose(outfile);

    printf("Time taken (OpenMP): %.4f seconds\n", elapsed_time);
    printf("Total primes found: %d\n", count);
    printf("Primes written to primes_openmp.txt\n");
    printf("Number of threads used: %d\n", num_threads);

    free(primes);
    return 0;
}
```

**OpenMP Scheduling Analysis:**

1. **Dynamic Scheduling Benefits:**
   - **Load balancing:** Threads get new work when they finish current chunk
   - **Optimal for irregular workloads:** Prime density varies across ranges
   - **Runtime adaptation:** Scheduler adapts to actual thread performance
   - **Minimal idle time:** Threads rarely wait for others to complete

2. **Chunk Size Optimization (100):**
   - **Too small (< 10):** High scheduling overhead
   - **Too large (> 1000):** Poor load balancing
   - **Optimal (100):** Good balance between overhead and distribution
   - **Cache-friendly:** Chunk fits well in CPU cache

3. **Critical Section Impact:**
   - **Minimal overhead:** Only during prime storage (rare operation)
   - **Short duration:** Simple array assignment operation
   - **No deadlock risk:** Single critical section per thread
   - **Alternative:** Could use reduction for better performance

**Advantages of OpenMP Approach:**
- **Excellent performance:** Near-optimal speedup with proper thread count
- **Easy implementation:** Minimal changes from serial code
- **Automatic optimization:** Compiler and runtime handle complexity
- **Portable:** Works across different systems and compilers
- **Scalable:** Performance improves with additional cores

**Minor Limitations:**
- **Critical section bottleneck:** Small overhead during result storage
- **Memory ordering:** Requires post-processing sort for ordered output
- **OpenMP dependency:** Requires OpenMP-capable compiler

---

## 3. Performance Results

### 3.1 Experimental Data

| Method | Threads | Time (s) | Speed-up | Efficiency |
|--------|---------|----------|----------|------------|
| **Serial** | 1 | 0.0723 | 1.00x | 100% |
| **POSIX Threads** | 4 | 0.1169 | 0.62x | 15.5% |
| **POSIX Threads** | 8 | 0.1109 | 0.65x | 8.1% |
| **POSIX Threads** | 16 | 0.1595 | 0.45x | 2.8% |
| **OpenMP** | 4 | 0.0341 | 2.12x | 53% |
| **OpenMP** | 8 | 0.0241 | 3.00x | 37.5% |
| **OpenMP** | 16 | 0.0653 | 1.11x | 6.9% |

**Speed-up Formula:** Speed-up = T_serial / T_parallel  
**Efficiency Formula:** Efficiency = Speed-up / Number_of_threads Ã— 100%

### 3.2 Performance Analysis

#### 3.2.1 POSIX Threads Results
- **All configurations slower than serial implementation**
- **Performance degradation increases with thread count**
- **Maximum slowdown: 2.2x with 16 threads (0.45x speed-up)**

#### 3.2.2 OpenMP Results
- **Consistent performance improvements across all thread counts**
- **Peak performance: 3.00x speedup with 8 threads**
- **Diminishing returns beyond 8 threads**

---

## 4. Detailed Analysis

### 4.1 POSIX Threads Analysis

#### 4.1.1 Speed-up Analysis
**Q: What is the speed-up? Is it reasonable?**

The POSIX Threads implementation shows **negative speed-up** across all configurations:
- 4 threads: 0.62x (38% slower)
- 8 threads: 0.65x (35% slower)  
- 16 threads: 0.45x (55% slower)

**This is not reasonable** and indicates fundamental implementation issues.

#### 4.1.2 Scalability Analysis
**Q: How does speed-up change when increasing/decreasing threads?**

Performance **degrades progressively** with more threads:
- **Root cause:** Thread overhead exceeds computational benefits
- **Memory allocation:** Each thread performs separate malloc operations
- **Cache inefficiency:** Poor memory locality across thread boundaries
- **Context switching:** Excessive overhead with thread management

#### 4.1.3 Task Distribution Evaluation
**Q: Is the task distribution approach good?**

The static range partitioning approach has **significant limitations:**

**Detailed Problem Analysis:**

1. **Load Imbalance Issue:**
   - **Prime density decreases** with larger numbers (Prime Number Theorem)
   - **Example:** Range [2-1000] has 168 primes, [999000-1000000] has ~48 primes
   - **Result:** Early threads finish much faster than later threads
   - **Impact:** CPU cores become idle while waiting for slowest thread

2. **Memory Management Problems:**
   - **Multiple malloc calls:** Each thread allocates separately
   - **Memory fragmentation:** Non-contiguous allocations hurt cache performance
   - **Over-allocation:** Each thread allocates `range` integers (wasteful)
   - **Memory bandwidth:** Multiple arrays compete for memory bandwidth

3. **Cache Efficiency Issues:**
   - **Poor spatial locality:** Threads work on different memory regions
   - **Cache line conflicts:** Multiple threads may access same cache lines
   - **NUMA effects:** Threads may access remote memory on multi-socket systems

4. **Synchronization Overhead:**
   - **Thread creation/destruction:** Expensive operations per execution
   - **Context switching:** OS overhead when managing multiple threads
   - **Memory barriers:** Implicit barriers hurt performance

**Concrete Example (n=1,000,000, 4 threads):**
```
Thread 0: [2 - 250,000]     â†’ ~22,000 primes, finishes fast
Thread 1: [250,000 - 500,000] â†’ ~15,000 primes, medium time
Thread 2: [500,000 - 750,000] â†’ ~12,000 primes, medium time  
Thread 3: [750,000 - 1,000,000] â†’ ~9,000 primes, slowest
```

**Recommended improvements:**
- **Shared memory allocation:** Single large array for all results
- **Work-stealing algorithms:** Dynamic redistribution of unfinished work
- **Smaller work units:** Divide into many small chunks rather than large ranges
- **Thread pool pattern:** Reuse threads instead of creating/destroying
- **NUMA-aware allocation:** Pin threads and memory to specific cores

### 4.2 OpenMP Analysis

#### 4.2.1 Speed-up Analysis
**Q: What is the speed-up? Is it reasonable?**

OpenMP demonstrates **excellent speed-up** characteristics:
- 4 threads: 2.12x speedup (reasonable)
- 8 threads: 3.00x speedup (excellent)
- 16 threads: 1.11x speedup (positive but diminished)

**This is very reasonable** and demonstrates effective parallelization.

#### 4.2.2 Scalability Analysis
**Q: How does speed-up change with different thread counts?**

OpenMP shows **optimal scaling pattern:**
- **Performance increases** from 4 to 8 threads
- **Peak performance** at 8 threads
- **Diminishing returns** beyond 8 threads due to:
  - Memory bandwidth saturation
  - Increased synchronization overhead
  - NUMA effects on multi-socket systems

#### 4.2.3 Task Distribution Evaluation
**Q: Is the task distribution approach efficient?**

The dynamic scheduling approach is **highly efficient:**

**Advantages:**
- **Automatic load balancing:** Work redistributed dynamically
- **Optimized memory usage:** Single shared allocation
- **Runtime optimization:** Compiler and library optimizations
- **NUMA-aware scheduling:** Better memory locality

**Minor limitations:**
- **Critical section overhead:** Serialization during result storage
- **Memory contention:** Shared access to result array

---

## 5. Comparative Analysis

### 5.1 Performance Comparison

**Performance Ranking:**
1. ðŸ¥‡ **OpenMP with 8 threads:** 3.00x speedup (Best)
2. ðŸ¥ˆ **OpenMP with 4 threads:** 2.12x speedup (Very Good)
3. ðŸ¥‰ **OpenMP with 16 threads:** 1.11x speedup (Good)
4. **Serial implementation:** 1.00x baseline
5. **POSIX Threads (all configs):** 0.45x - 0.65x (Poor)

### 5.2 Key Insights

#### 5.2.1 Why OpenMP Outperforms POSIX Threads
1. **Superior load balancing** through dynamic scheduling
2. **Lower runtime overhead** with optimized thread management
3. **Better memory management** with shared allocations
4. **Compiler optimizations** specific to parallel loops
5. **NUMA-aware** thread placement and scheduling

#### 5.2.2 Optimal Configuration
- **8 threads provide peak performance** for this workload
- **Beyond 8 threads:** Diminishing returns due to overhead
- **Hardware utilization:** 40% of available cores optimal

### 5.3 Algorithm Characteristics Impact
- **Embarrassingly parallel problem:** Prime checking is independent
- **Irregular workload:** Prime density varies across ranges
- **Memory-bound aspects:** Large result arrays affect performance
- **Cache sensitivity:** Memory access patterns crucial

---

## 6. Conclusions and Recommendations

### 6.1 Main Conclusions

1. **OpenMP is significantly superior** for this type of parallel computing task
2. **POSIX Threads implementation requires fundamental redesign** to be viable
3. **Dynamic scheduling outperforms static partitioning** for irregular workloads
4. **Optimal thread count depends on workload characteristics**, not just core count
5. **Memory management strategy critically impacts performance**

### 6.2 Practical Recommendations

#### 6.2.1 For Production Use
- **Choose OpenMP** for embarrassingly parallel problems
- **Use 8 threads** for optimal performance on this hardware
- **Monitor for diminishing returns** when scaling thread count
- **Consider algorithm-specific optimizations** beyond parallelization

#### 6.2.2 For POSIX Threads Improvement
- **Redesign memory allocation strategy** (use shared arrays)
- **Implement dynamic work distribution** (work-stealing queues)
- **Optimize for cache locality** in task assignment
- **Reduce thread creation overhead** with thread pools

### 6.3 Future Work
- **Investigate vectorization** (SIMD) for additional performance gains
- **Explore GPU acceleration** for larger problem sizes
- **Analyze different scheduling strategies** in OpenMP
- **Study NUMA effects** on larger multi-socket systems

---

## 7. References and Tools

### 7.1 Development Environment
- **Compiler:** GCC with `-fopenmp`, `-lpthread`, `-lm` flags
- **Profiling:** Built-in timing functions (`clock()`, `omp_get_wtime()`)
- **Testing:** Multiple runs with different thread configurations

### 7.2 Code Files Submitted
- `task1.c` - Serial implementation
- `task2.c` - POSIX Threads implementation  
- `task3.c` - OpenMP implementation
- Output files: `primes_serial.txt`, `primes_parallel.txt`, `primes_openmp.txt`

### 7.3 Verification
All implementations correctly identify **78,498 prime numbers** less than 1,000,000, ensuring algorithmic correctness across all approaches.

---

## Appendix A: Performance Charts

```
Speed-up Comparison Chart:

OpenMP Performance:
4 threads  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.12x
8 threads  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3.00x
16 threads â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.11x

POSIX Threads Performance:
4 threads  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.62x (slower)
8 threads  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.65x (slower)
16 threads â–ˆâ–ˆâ–ˆâ–ˆ 0.45x (slower)

Serial Baseline: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.00x
```

---

**Declaration:** This work was completed independently using the provided lab instructions and system resources. No AI tools were used during the implementation and testing phases.
